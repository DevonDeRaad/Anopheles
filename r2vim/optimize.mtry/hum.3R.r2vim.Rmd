---
title: "3R.hum.r2vim"
author: "Devon DeRaad"
date: "8/25/2020"
output: html_document
---

```{r}
# Random Forest using regression trees

# The code relies on the package randomForest (Liaw and Wiener 2002)
#install.packages("randomForest")
library(randomForest)

#install Pomona to use the ranger wrapper function to execute r2vim protocol
#install.packages("remotes")
#remotes::install_github("silkeszy/Pomona")
library(Pomona)
library(ranger)
library(parallel)
```

```{r}
#read in environmental and population information
env.pop<-read.csv("env.pop.csv")

#read in 3R chrom SNP matrix, drop column 1, which is rowname
snp.matrix<-read.table("maf05.ld100.matrix.3R.012")[,-1]

#drop all columns in the snp matrix containing missing data
snp.matrix<-snp.matrix[,colSums(is.na(snp.matrix)) == 0]

#create reg_data including pop, hum variable, and 3R chrom SNP matrix
reg_data<-as.data.frame(cbind(env.pop$population,env.pop$h_mean,snp.matrix))

#rename columns to match pop and response
colnames(reg_data)[1:2]<-c("pop","response")

# First, explore the overall distribution of the phenotype
hist(reg_data$response)   
```

```{r, echo=T, results='hide'}
#we should correct for pop stratification before conducting RF to minimize the risk of false positive associations.
#Specifically, we will correct the genotypes and phenotypes using the approach of Zhao et al.(2012). 

reg_data_corrected <- reg_data # create another data frame for the corrected phenotypes and genotypes
# Keep the first column with population ID, but then replace with NA's over which you can write the residuals.
reg_data_corrected[,2:ncol(reg_data_corrected)] <- NA

# Now correct the genotypes and phenotypes using the regression/residual method.
#We're using a standard linear regression because Zhao et al. 2012 
#found that the correction procedure is robust to selection of the link function
for (i in 2:ncol(reg_data)){
  LM_SNP_i <- lm(reg_data[,i] ~ factor(reg_data$pop)) # apply linear model to all loci and the response
  reg_data_corrected[,i] <- LM_SNP_i$residuals
  colnames(reg_data_corrected)[i]<-colnames(reg_data)[i] 
  if(i%%50==0) print(i)
}
```

```{r}
# Verify that the residuals have been written to the data frame properly, using the last column as an example
reg_data_corrected[,ncol(reg_data_corrected)]-LM_SNP_i$residuals  #Should all be zero if correct
class(reg_data_corrected$response) #must be numeric

# Export a copy of the corrected genotypes and phenotypes for future reference (This corresponds to the data in Table S6)
write.csv(reg_data_corrected,file="3R.hum.corrected.csv", row.names = FALSE, quote=FALSE)
```

```{r}
## Now run Random Forest analysis. Since this is a continuous trait, we need to conduct a regression RF
#
## First, we need to optimize mtry by running different values of mtry at different values of ntree. 
#
## We will run mtry values of sqrt(p), 2*sqrt(p), 0.1(p), 0.2(p), p/3, and p, where p is the number of loci
## We will initially run each of these mtry values at ntree=100 to 1000 (by increments of 100). 
## We are looking for a plateau where the proportion variation explained (PVE) stops increasing with larger values of ntree
## Once we reach the plateau, we will choose the mtry value that maximizes PVE.
p<-ncol(reg_data_corrected)-2
results_optimization <- matrix(data=NA , nrow = 0, ncol = 3)
for (i in seq(from = 100, to = 1000 , by = 100)){  # values of ntree
  print(i)
  for (j in c(sqrt(p), 2*sqrt(p), 0.1*p, 0.2*p, p/3, p)){    #values of mtry based on 1000 total loci
    rf_ij <- ranger(x = reg_data_corrected[,3:ncol(reg_data_corrected)], y = reg_data_corrected$response, num.trees=i, mtry=j)
    results_optimization <- rbind(results_optimization, c(i,j,tail(rf_ij$r.squared,1)))
  }
}

# Clean up the file format
results_optimization<-as.data.frame(results_optimization)
colnames(results_optimization)<-c("ntree", "mtry","PVE")

# Now plot results to see if there's a plateau
plot(results_optimization$ntree[results_optimization$mtry == sqrt(p)],results_optimization$PVE[results_optimization$mtry == sqrt(p)], type="l", col="black", xlab="ntree",ylab="PVE", ylim=range(results_optimization$PVE))
lines(results_optimization$ntree[results_optimization$mtry == 2*sqrt(p)],results_optimization$PVE[results_optimization$mtry == 2*sqrt(p)], col="blue")
lines(results_optimization$ntree[results_optimization$mtry == 0.1*p],results_optimization$PVE[results_optimization$mtry == 0.1*p], col="green")
lines(results_optimization$ntree[results_optimization$mtry == 0.2*p],results_optimization$PVE[results_optimization$mtry == 0.2*p], col="purple")
lines(results_optimization$ntree[results_optimization$mtry == p/3],results_optimization$PVE[results_optimization$mtry == p/3], col="orange")
lines(results_optimization$ntree[results_optimization$mtry == p],results_optimization$PVE[results_optimization$mtry == p], col="red")

# This plot shows which value of mtry is the best (in terms of PVE), and that the PVE has reached a plateau. 
# We will use out optimized mtry value now for our Random Forest analyses.
```

```{r}
##read in adjusted df
#reg_data_corrected<-read.csv("~/Downloads/3R.hum.corrected.csv")
#p<-ncol(reg_data_corrected)-2
#
##read in position info
#pos<-read.csv("3R.chrom.no.missing.pos.csv")
#
##execute 10 random forests with 1000 trees each, and the optimized mtry value: via this wrapper function for #ranger
#r2vim<-var.sel.r2vim(x = reg_data_corrected[,3:ncol(reg_data_corrected)], y=reg_data_corrected$response,
#              no.runs = 10, factor = 1, ntree = 1000, mtry.prop = .2*p,
#              method = "ranger", type = "regression")
#
##calculate correlation between runs to ensure ntree=1000 was high enough to achieve convergence
#runs<-as.data.frame(cbind(r2vim$info$vim.run.1,r2vim$info$vim.run.2,r2vim$info$vim.run.3,r2vim$info$vim.run.4,r2#vim$info$vim.run.5,
#                          r2vim$info$vim.run.6,r2vim$info$vim.run.7,r2vim$info$vim.run.8,r2vim$info$vim.run.9,r2#vim$info$vim.run.10))
##calc correlation
#cor(runs)
#hist(cor(runs)) #check how they all compare
#plot(runs[,1],runs[,2]) #compare run 1 and 2 visually
#
##make results df for manhattan plot
#df<-data.frame(chrom=pos$chrom,
#               snp=pos$snp,
#               min.rel.vim=r2vim$info$rel.vim.min)
#
##plot
#plot(x=1:nrow(df),y=r2vim$info$rel.vim.min)
#abline(h=1, col="red")
#
##save rel.vim.min values
#write.csv(df, "3R.hum.rel.vim.min.csv", row.names=FALSE, quote=FALSE)

```

